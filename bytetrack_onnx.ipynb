{"cells":[{"cell_type":"code","source":["import sys\n","from google.colab import drive\n","drive.mount('/content/gdrive/')\n","sys.path.append('/content/gdrive/MyDrive/Colab Notebooks/ByteTrack/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iRxUjaB1Dr0x","executionInfo":{"status":"ok","timestamp":1660946537896,"user_tz":240,"elapsed":1257,"user":{"displayName":"Akarsh Pokkunuru","userId":"15843579918219361792"}},"outputId":"76fd85a3-dcfc-46ae-810d-f47b094c7798"},"id":"iRxUjaB1Dr0x","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd '/content/gdrive/MyDrive/Colab Notebooks/ByteTrack/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9gBxfNewDr6j","executionInfo":{"status":"ok","timestamp":1660946537897,"user_tz":240,"elapsed":8,"user":{"displayName":"Akarsh Pokkunuru","userId":"15843579918219361792"}},"outputId":"613d8357-328f-4b96-dbfa-edf0d02e5d06"},"id":"9gBxfNewDr6j","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Colab Notebooks/ByteTrack\n"]}]},{"cell_type":"code","source":["# !pip3 install -r requirements.txt"],"metadata":{"id":"-I3PXkgHD3KQ"},"id":"-I3PXkgHD3KQ","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"ce13a34c","metadata":{"id":"ce13a34c"},"outputs":[],"source":["import os\n","import cv2\n","import torch\n","from torch import nn\n","import numpy as np\n","\n","from yolox.exp import get_exp\n","from yolox.models.network_blocks import SiLU\n","from yolox.utils import replace_module\n","\n","import onnx\n","from onnxsim import simplify\n","\n","import argparse\n","import onnxruntime\n","from yolox.data.data_augment import preproc as preprocess\n","from yolox.utils import mkdir, multiclass_nms, demo_postprocess, vis\n","from yolox.utils.visualize import plot_tracking\n","from yolox.tracker.byte_tracker import BYTETracker\n","from yolox.tracking_utils.timer import Timer"]},{"cell_type":"code","execution_count":null,"id":"fd074558","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fd074558","executionInfo":{"status":"ok","timestamp":1660946566126,"user_tz":240,"elapsed":18047,"user":{"displayName":"Akarsh Pokkunuru","userId":"15843579918219361792"}},"outputId":"1fb7e037-1559-499f-d2a9-53d62c167898"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 3, 608, 1088])\n"]}],"source":["save_onnx_model = True\n","\n","if save_onnx_model:\n","    # exp = get_exp('exps/example/mot/yolox_x_mix_det.py', None)\n","    exp = get_exp('exps/example/mot/yolox_s_mix_det.py', None)\n","\n","    model = exp.get_model().to(torch.device(\"cpu\"))\n","    model.eval()\n","\n","    # ckpt = torch.load('pretrained/bytetrack_x_mot17.pth.tar', map_location=\"cpu\")\n","    ckpt = torch.load('pretrained/bytetrack_s_mot17.pth.tar', map_location=\"cpu\")\n","\n","    model.load_state_dict(ckpt[\"model\"])\n","    model = replace_module(model, nn.SiLU, SiLU)\n","    model.head.decode_in_inference = False\n","    dummy_input = torch.randn(1, 3, exp.test_size[0], exp.test_size[1])\n","    print(dummy_input.shape)\n","\n","    onnx_path = \"./onnx/model_s.onnx\"\n","\n","    torch.onnx._export(model, dummy_input, onnx_path, \n","                       input_names=['images'], output_names=['output'],\n","                       opset_version=11)\n","    \n","    onnx_model = onnx.load(onnx_path)\n","    model_simp, check = simplify(onnx_model)\n","    assert check, \"Simplified ONNX model could not be validated\"\n","    onnx.save(model_simp, onnx_path)"]},{"cell_type":"code","execution_count":null,"id":"061c9f4b","metadata":{"id":"061c9f4b"},"outputs":[],"source":["# onnx_path = \"./onnx/model.onnx\"\n","# model = cv2.dnn.readNetFromONNX(onnx_path)\n","\n","# image = cv2.imread('./assets/test.jpg')\n","# blob = cv2.dnn.blobFromImage(image, 1.0 / 255, (224, 224),(0, 0, 0), swapRB=True, crop=False)\n","# net.setInput(blob)\n","# preds = net.forward()\n","# print (\"Predicted\", preds.shape)"]},{"cell_type":"code","execution_count":null,"id":"29fa15d1","metadata":{"id":"29fa15d1"},"outputs":[],"source":["def make_parser():\n","    parser = argparse.ArgumentParser(\"onnxruntime inference sample\")\n","    parser.add_argument(\n","        \"-m\",\n","        \"--model\",\n","        type=str,\n","        default=\"onnx/model_s.onnx\",\n","        help=\"Input your onnx model.\",\n","    )\n","    parser.add_argument(\n","        \"-i\",\n","        \"--video_path\",\n","        type=str,\n","        default='videos/palace.mp4',\n","        help=\"Path to your input image.\",\n","    )\n","    parser.add_argument(\n","        \"-o\",\n","        \"--output_dir\",\n","        type=str,\n","        default='demo_output',\n","        help=\"Path to your output directory.\",\n","    )\n","    parser.add_argument(\n","        \"-s\",\n","        \"--score_thr\",\n","        type=float,\n","        default=0.1,\n","        help=\"Score threshould to filter the result.\",\n","    )\n","    parser.add_argument(\n","        \"-n\",\n","        \"--nms_thr\",\n","        type=float,\n","        default=0.7,\n","        help=\"NMS threshould.\",\n","    )\n","    parser.add_argument(\n","        \"--input_shape\",\n","        type=str,\n","        default=\"608,1088\",\n","        help=\"Specify an input shape for inference.\",\n","    )\n","    parser.add_argument(\n","        \"--with_p6\",\n","        action=\"store_true\",\n","        help=\"Whether your model uses p6 in FPN/PAN.\",\n","    )\n","    # tracking args\n","    parser.add_argument(\"--track_thresh\", type=float, default=0.5, help=\"tracking confidence threshold\")\n","    parser.add_argument(\"--track_buffer\", type=int, default=30, help=\"the frames for keep lost tracks\")\n","    parser.add_argument(\"--match_thresh\", type=float, default=0.8, help=\"matching threshold for tracking\")\n","    parser.add_argument('--min-box-area', type=float, default=10, help='filter out tiny boxes')\n","    parser.add_argument(\"--mot20\", dest=\"mot20\", default=False, action=\"store_true\", help=\"test mot20.\")\n","    return parser\n","\n","class Predictor(object):\n","    def __init__(self, args):\n","        self.rgb_means = (0.485, 0.456, 0.406)\n","        self.std = (0.229, 0.224, 0.225)\n","        self.args = args\n","        self.session = onnxruntime.InferenceSession(args.model)\n","        self.input_shape = tuple(map(int, args.input_shape.split(',')))\n","    \n","    def inference(self, ori_img, timer):\n","        img_info = {\"id\": 0}\n","        height, width = ori_img.shape[:2]\n","        img_info[\"height\"] = height\n","        img_info[\"width\"] = width\n","        img_info[\"raw_img\"] = ori_img\n","        \n","        img, ratio = preprocess(ori_img, self.input_shape, self.rgb_means, self.std)\n","        img_info[\"ratio\"] = ratio\n","        ort_inputs = {self.session.get_inputs()[0].name: img[None, :, :, :]}\n","        timer.tic()\n","        output = self.session.run(None, ort_inputs)\n","        predictions = demo_postprocess(output[0], self.input_shape, p6=self.args.with_p6)[0]\n","        \n","        boxes = predictions[:, :4]\n","        scores = predictions[:, 4:5] * predictions[:, 5:]\n","        \n","        boxes_xyxy = np.ones_like(boxes)\n","        boxes_xyxy[:, 0] = boxes[:, 0] - boxes[:, 2]/2.\n","        boxes_xyxy[:, 1] = boxes[:, 1] - boxes[:, 3]/2.\n","        boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2]/2.\n","        boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3]/2.\n","        boxes_xyxy /= ratio\n","        dets = multiclass_nms(boxes_xyxy, scores, nms_thr=self.args.nms_thr, score_thr=self.args.score_thr)\n","        return dets[:, :-1], img_info\n","\n","\n","def imageflow_demo(predictor, args):\n","    cap = cv2.VideoCapture(args.video_path)\n","    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # float\n","    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    save_folder = args.output_dir\n","    os.makedirs(save_folder, exist_ok=True)\n","    save_path = os.path.join(save_folder, args.video_path.split(\"/\")[-1])\n","    print(f\"video save_path is {save_path}\")\n","    vid_writer = cv2.VideoWriter(\n","        save_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (int(width), int(height))\n","    )\n","    tracker = BYTETracker(args, frame_rate=30)\n","    timer = Timer()\n","    frame_id = 0\n","    results = []\n","    while True:\n","        if frame_id % 20 == 0:\n","            print('Processing frame {} ({:.2f} fps)'.format(frame_id, 1. / max(1e-5, timer.average_time)))\n","        ret_val, frame = cap.read()\n","        if ret_val:\n","            outputs, img_info = predictor.inference(frame, timer)\n","            online_targets = tracker.update(outputs, [img_info['height'], img_info['width']], [img_info['height'], img_info['width']])\n","            online_tlwhs = []\n","            online_ids = []\n","            online_scores = []\n","            for t in online_targets:\n","                tlwh = t.tlwh\n","                tid = t.track_id\n","                vertical = tlwh[2] / tlwh[3] > 1.6\n","                if tlwh[2] * tlwh[3] > args.min_box_area and not vertical:\n","                    online_tlwhs.append(tlwh)\n","                    online_ids.append(tid)\n","                    online_scores.append(t.score)\n","            timer.toc()\n","            results.append((frame_id + 1, online_tlwhs, online_ids, online_scores))\n","            online_im = plot_tracking(img_info['raw_img'], online_tlwhs, online_ids, frame_id=frame_id + 1,\n","                                      fps=1. / timer.average_time)\n","            vid_writer.write(online_im)\n","            ch = cv2.waitKey(1)\n","            if ch == 27 or ch == ord(\"q\") or ch == ord(\"Q\"):\n","                break\n","        else:\n","            break\n","        frame_id += 1"]},{"cell_type":"code","execution_count":null,"id":"40ae587b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"40ae587b","executionInfo":{"status":"ok","timestamp":1660946629854,"user_tz":240,"elapsed":169,"user":{"displayName":"Akarsh Pokkunuru","userId":"15843579918219361792"}},"outputId":"2495edd0-8e6f-4253-cd4d-01f4a7e43358"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Namespace(input_shape='608,1088', match_thresh=0.8, min_box_area=10, model='onnx/model_s.onnx', mot20=False, nms_thr=0.7, output_dir='demo_output', score_thr=0.1, track_buffer=30, track_thresh=0.5, video_path='videos/palace.mp4', with_p6=False)"]},"metadata":{},"execution_count":6}],"source":["import sys\n","sys.argv=['']\n","del sys\n","\n","args = make_parser().parse_args()\n","args"]},{"cell_type":"code","execution_count":null,"id":"9ee56ce0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ee56ce0","executionInfo":{"status":"ok","timestamp":1660946911779,"user_tz":240,"elapsed":279683,"user":{"displayName":"Akarsh Pokkunuru","userId":"15843579918219361792"}},"outputId":"98001e2b-fcf0-4603-dd11-faac0cf5c320"},"outputs":[{"output_type":"stream","name":"stdout","text":["video save_path is demo_output/palace.mp4\n","Processing frame 0 (100000.00 fps)\n","Processing frame 20 (1.31 fps)\n","Processing frame 40 (1.25 fps)\n","Processing frame 60 (1.28 fps)\n","Processing frame 80 (1.26 fps)\n","Processing frame 100 (1.28 fps)\n","Processing frame 120 (1.29 fps)\n","Processing frame 140 (1.26 fps)\n","Processing frame 160 (1.27 fps)\n","Processing frame 180 (1.26 fps)\n","Processing frame 200 (1.27 fps)\n","Processing frame 220 (1.28 fps)\n","Processing frame 240 (1.28 fps)\n","Processing frame 260 (1.28 fps)\n","Processing frame 280 (1.28 fps)\n","Processing frame 300 (1.28 fps)\n","Processing frame 320 (1.28 fps)\n"]}],"source":["predictor = Predictor(args)\n","imageflow_demo(predictor, args)"]},{"cell_type":"code","execution_count":null,"id":"5218d04c","metadata":{"id":"5218d04c"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"bytetrack_onnx.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}